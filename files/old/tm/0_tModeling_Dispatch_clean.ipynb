{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling the Dispatch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**NB:** this is now the only part!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ast import literal_eval # for loading columns with lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to ensure that data in the columns is in the formats that it must be for further processing: namely, we need to ensure that dates are in the date format (we did that before), but most importantly that our generated columns with *lists* of words are lists and not strings (that is how they will be loaded from a CSV file by default). The latter can be done during loading (`literal_eval`).\n",
    "\n",
    "**Note:** we can actually reduce the size of the `Dispatch_Light_Preprocessed.tsv` by removing columns that we do not really need anymore: `textData` and `textDataLists` (we only need `textDataListsFiltered`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following should load preprocessed Dispatch data for 1860-1864. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE CAN EDIT THIS LIST IN ORDER TO REDUCE THE AMOUNT OF DATA THAT WE ARE LOADING\n",
    "dispatchSubfolder = \"./Dispatch_Processed_TSV/\"\n",
    "dispatchFiles = [\"Dispatch_1860_tmReady.tsv\",  # incomplete\n",
    "                 \"Dispatch_1861_tmReady.tsv\",  # The War starts of April 12, 1861\n",
    "                 \"Dispatch_1862_tmReady.tsv\",\n",
    "                 \"Dispatch_1863_tmReady.tsv\",\n",
    "                 \"Dispatch_1864_tmReady.tsv\",\n",
    "                 #\"Dispatch_1865_tmReady.tsv\",  # incomplete - The War ends on May 9, 1865\n",
    "                 ]\n",
    "\n",
    "df = pandas.DataFrame()\n",
    "\n",
    "for f in dispatchFiles:\n",
    "    dfTemp = pandas.read_csv(dispatchSubfolder + f, sep=\"\\t\", header=0, converters={'textDataLists': literal_eval})\n",
    "    df = df.append(dfTemp)\n",
    "\n",
    "dispatch_light = df\n",
    "# drop=True -- use it to avoid creating a new column with the old index values\n",
    "dispatch_light = dispatch_light.reset_index(drop=True) \n",
    "\n",
    "dispatch_light[\"month\"] = [re.sub(\"-\\d\\d$\", \"\", str(i)) for i in dispatch_light[\"date\"]]\n",
    "dispatch_light[\"month\"] = pandas.to_datetime(dispatch_light[\"month\"], format=\"%Y-%m\")\n",
    "dispatch_light[\"date\"] = pandas.to_datetime(dispatch_light[\"date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispatch_light = dispatch_light.dropna() # you may want to use this line in the future in case you want to exclude rows of data that have NaN values (not analyzable)\n",
    "dispatch_light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dictionary and Corpus Objects needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create Dictionary\n",
    "dictionary = gensim.corpora.Dictionary(dispatch_light[\"textDataLists\"])\n",
    "\n",
    "# Create Corpus\n",
    "texts = dispatch_light[\"textDataLists\"]\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] # bow == bag of words\n",
    "\n",
    "# View\n",
    "print(corpus[:1])\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list above is a text: every tuple (like `(0, 1)`) represents a word (first number) and its frequency (second number). We can check which word is hiding behind a number by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the word `president` occurs three times in the article. And this is the complete text hiding behinf this numeric abstraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_light[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of topics is a tricky issue, since we pre-determine this number and the algorithm then splits all data into that number of topics. In other words, if you tell the machine to find 10 topics, it will use 10 buckets to sort all the data into; if you give it 20, it will do that for 20. For this reason topic modeling often takes multiple attempts. Additionally, it is not uncommon to then pull out a specific topic from your data and re-run the algorithm on that subset of texts. \n",
    "\n",
    "Nonetheless, there is a mathematical way to identify the optimal number of topics. The common practice is to generate several models and calculate `coherence score` (*k*) for them all—the number with the highest `coherence score` is considered optimal (ideally, above 0.55). \n",
    "\n",
    "**NB**: Do not run the code below during the class, as it took about 67 minutes to complete (this time may differ significantly depending on the configuration of your machine).\n",
    "\n",
    "**NB:** You can comment out the entire chunk by selecting it and pressing `Ctrl+/` on Windows or `Cmd+/` on Mac. Pressing these combinations again will make code runnable again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below I have added one more parameter: `random_state`. This parameter is crucial for reproducability. The issue with generating statistical models is that they always get generated slightly differently. In order to avoid this, we can use `random_state` parameter with the same number (`random_state = 2023`); the number itself is not important; what is important is that you reuse the **same** number, which will guarantee the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# optimalTopicsNumber = [\"topics\\tscore\"]\n",
    "\n",
    "# for num in range(4, 51, 1):\n",
    "#     lda_model_temp = gensim.models.LdaModel(corpus=corpus,id2word=dictionary, num_topics=num, random_state=2023)\n",
    "#     coherence_model_lda = CoherenceModel(model=lda_model_temp,texts=dispatch_light[\"textDataLists\"],\n",
    "#                                      dictionary=dictionary, coherence='c_v')\n",
    "#     coherence_lda = coherence_model_lda.get_coherence()\n",
    "#     optimalTopicsNumber.append(\"%d\\t%f\" % (num, coherence_lda))\n",
    "\n",
    "#     print('Coherence Score for %02d topics: ' % num, coherence_lda)\n",
    "    \n",
    "# print(\"-\"*50)\n",
    "\n",
    "# optimalTopicsNumber = \"\\n\".join(optimalTopicsNumber)\n",
    "# print(optimalTopicsNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really necessary, but we can plot these results in the following manner (score above 0.55 should be ok):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "scores = \"\"\"topics\tscore\n",
    "4\t0.492556\n",
    "5\t0.520064\n",
    "6\t0.531907\n",
    "7\t0.528860\n",
    "8\t0.539734\n",
    "9\t0.517753\n",
    "10\t0.554835\n",
    "11\t0.537774\n",
    "12\t0.554257\n",
    "13\t0.561778\n",
    "14\t0.553429\n",
    "15\t0.534285\n",
    "16\t0.516632\n",
    "17\t0.528319\n",
    "18\t0.542015\n",
    "19\t0.544126\n",
    "20\t0.510367\n",
    "21\t0.519284\n",
    "22\t0.508858\n",
    "23\t0.522271\n",
    "24\t0.515742\n",
    "25\t0.514178\n",
    "26\t0.501335\n",
    "27\t0.487533\n",
    "28\t0.509954\n",
    "29\t0.509522\n",
    "30\t0.522582\n",
    "31\t0.500205\n",
    "32\t0.501318\n",
    "33\t0.493806\n",
    "34\t0.490917\n",
    "35\t0.493692\n",
    "36\t0.464409\n",
    "37\t0.487567\n",
    "38\t0.489053\n",
    "39\t0.476119\n",
    "40\t0.475229\n",
    "41\t0.462814\n",
    "42\t0.473426\n",
    "43\t0.482906\n",
    "44\t0.475647\n",
    "45\t0.477711\n",
    "46\t0.462434\n",
    "47\t0.468734\n",
    "48\t0.456667\n",
    "49\t0.463903\n",
    "50\t0.454378\n",
    "\"\"\"\n",
    "\n",
    "scoresData = io.StringIO(scores)\n",
    "scoresDF = pandas.read_csv(scoresData, sep=\"\\t\", header=0)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 9)\n",
    "plt.stem(scoresDF['topics'], scoresDF['score'])\n",
    "plt.plot([4, 50], [0.55, 0.55], color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.ylabel(\"coherence score\")\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.title(\"Coherence Score Test for TM of the Dispatch\")\n",
    "plt.gca().yaxis.grid(linestyle=':')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have several \"sweet spots\" where the corpus breaks down into a coherent number of topics—essentially, all above  or very close to 0.55. If you are doing an in-depth study of some corpus, it makes sense to generate models for all meaningful matches and explore the results in the manner that is described below. You are likely to observe that certain meaningful topics will appear at some point and will disappear as you change the number of topics.\n",
    "\n",
    "However, I suggest we go with the number of topics that was used in Robert K. Nelson's “Mining the Dispatch” (<https://dsl.richmond.edu/dispatch/>), which was 40. This way we should get results vlose to his and we can then use his work as a reference point for our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step usually takes quite a lot of time, so do not run it in class. You may want to leave it running overnight. Ideally, the number of passes should be at least a hundred—this increases the stability of topics, but also increases the amount of time required for generating the model. Good news is that you do not have to train the model every time: you can save it and load everytime you want to use it.\n",
    "\n",
    "On all the data (and we have a very large corpus), with 100 passes and 20 updates it is likely to take several hours to train a single model (see below).\n",
    "\n",
    "```\n",
    "CPU times: user 3h 30min 39s, sys: 1h 32min 40s, total: 5h 3min 20s\n",
    "Wall time: 41min 20s\n",
    "```\n",
    "\n",
    "**NB:** You can comment out the entire chunk by selecting it and pressing `Ctrl+/` on Windows or `Cmd+/` on Mac. Pressing these combinations again will make code runnable again.\n",
    "\n",
    "We can also train a quick and simple model with the default parameters of the training function (commented out: `#update_every=20, passes=100, alpha='auto',`). On my computer it took only about 2 mins, but it may differ significantly depending on the configuration of your machine. Overall, be prepared to take a long coffee break (just make sure your computer does not go to sleep in the meantime!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = 40\n",
    "number_of_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary,\n",
    "                                   random_state=2023,\n",
    "                                   #update_every=20, passes=100, alpha='auto',\n",
    "                                   num_topics=number_of_topics)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just a couple of lines of code for saving your model; since we are not generating one, they are commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(dispatchSubfolder + \"model_dispatch_1860_1864_%d.lda\" % number_of_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines will load the pre-generated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model = gensim.models.LdaModel.load(dispatchSubfolder + \"model_dispatch_1860_1864_%d.lda\" % number_of_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View generated topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in topics\n",
    "topicsData = lda_model.print_topics(num_topics = number_of_topics, num_words=10)\n",
    "pprint(topicsData)\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the following code for now. It simply converts the topic modeling data into a network format (one of possibilities) for an alternative exploration of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topicsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsDataNW = lda_model.print_topics(num_topics = number_of_topics, num_words=20)\n",
    "\n",
    "topicsTidy = []\n",
    "topicsDicQuick = {}\n",
    "\n",
    "for t in topicsDataNW:\n",
    "    topicsDicQuick[t[0]] = t[1]\n",
    "    words = t[1].split(\" + \")\n",
    "    for w in words:\n",
    "        w = w.replace('\"', \"\").replace(\"*\", \"\\t\")\n",
    "        topicsTidy.append(\"%s\\tT%02d\\t%s\" % (t[0], int(t[0])+1, w))\n",
    "\n",
    "topicsTidy = \"\\n\".join(topicsTidy)\n",
    "\n",
    "with open(dispatchSubfolder + \"tmTidy.tsv\", \"w\", encoding=\"utf8\") as f9:\n",
    "    f9.write(\"topic\\ttopicName\\tscore\\tterm\\n\" + topicsTidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we infer topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize topic-keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyLDAvis` library offers a visual tool for exploring topics. **λ-parameter** is designed to \"slice\" topics words in such a way that topics would be easier to interpret. If you slide this parameter below 1, you will see that the selection of words changes and if you reach 0, only words unique to this topic will be shown.\n",
    "\n",
    "**NB:** Keep in mind that on the visualization topics are numbered from 1, not from 0 as in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "modelVis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "# you are likely to see lots of red-ish text --- just ignore it... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(modelVis, dispatchSubfolder + 'tmVis_%02d_Topics_in_Dispatch_1860_1864.html' % number_of_topics)\n",
    "modelVis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's explore our topics more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_light.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_document_topics` for the entire corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get `doc_topics`, `word_topics` and `phi_values` (probabilities of words for topics) for all the documents in the corpus in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_topics = lda_model.get_document_topics(corpus, per_word_topics=True)\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out data for the first document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for doc_topics, word_topics, phi_values in all_topics[:1]:\n",
    "    print('New Document')\n",
    "    print('\\nDocument topics:', doc_topics)\n",
    "    print('\\nWord topics:', word_topics)\n",
    "    print('\\nPhi values:', phi_values)\n",
    "    #print(\" \")\n",
    "    print('-------------- \\n')\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a dataframe with topic values for every item (article) from the Dispatch. This will allow us to do more interesting things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "topicTableCols = [] # empty table for topic values (technically, a list still)\n",
    "topicDic = {} # a dictionary with top words per topic\n",
    "\n",
    "for i in range(0, number_of_topics, 1):\n",
    "    tVal = \"T%02d\" % (i + 1)\n",
    "    topicTableCols.append(tVal)\n",
    "    \n",
    "    topicVals  = lda_model.show_topic(i)\n",
    "    topicWords = \", \".join([word for word, prob in topicVals])\n",
    "    topicDic[tVal] = topicWords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(topicDic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step may take a couple minutes.\n",
    "\n",
    "- Here were creating an empty row (filled with zeros) for each document in our corpus;\n",
    "- then we loop through all topic values for every given document;\n",
    "- and feed existing values into our row with zeros (if we have a value, it will replace a zero);\n",
    "- you can insert `print`/`input` statements in the code below to see the steps of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code takes quite a while, so do not run it in class:\n",
    "\n",
    "```\n",
    "--------------------------------------------------\n",
    "CPU times: user 18min 41s, sys: 25min 56s, total: 44min 38s\n",
    "Wall time: 6min 58s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "topicTableRows = [] # now we are feeding topic values into our empty table\n",
    "\n",
    "for doc_topics, word_topics, phi_values in all_topics:\n",
    "    rawRow = [0] * number_of_topics\n",
    "    for t in doc_topics:\n",
    "        rawRow[t[0]] = t[1]\n",
    "    topicTableRows.append(rawRow)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different topics in the 0th document/article\n",
    "topicTableRows[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our corpus table length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dispatch_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our topic table length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topicTableRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to convert it into a proper dataframe format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicTable = pandas.DataFrame(topicTableRows, columns=topicTableCols)\n",
    "topicTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our topic table has the same dimensions (number of rows) as our Dispatch data, the rows in the topic table are indexed differently (starting from 0, while the Dispatch data starts from 1). We need to fix that before we can join topics table to the Dispatch data. Since default count in Python is from 0, it is easier to reset the Dispatch data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_light = dispatch_light.reset_index(drop=True)\n",
    "dispatch_light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can merge them without any issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedTable = pandas.concat([dispatch_light, topicTable], axis=1, sort=False)\n",
    "len(mergedTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedTable.loc[[3947]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(mergedTable[\"text\"][3947])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing topics over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most interesting things that we can do with data like ours is to check how topics are distributed over time. Our data is already prepared for this, we only need to summarize topics values by days or months before we can graph them (for more [details](https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/)). `pandas` library has all we need, but there many specialized graphing libraries that may produce better visual results. (For more details, check this [overview](https://www.shanelynn.ie/plotting-with-python-and-pandas-libraries-for-data-visualisation/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicSum = mergedTable.groupby(\"month\").mean().copy() # This will find the average mean for each topic for each month\n",
    "topicSum[\"month\"] = topicSum.index\n",
    "topicSum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot all our topics and see their progression over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic = \"T32\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 9)\n",
    "plt.plot(topicSum['month'], topicSum[topic])\n",
    "\n",
    "plt.ylabel(\"topic salience (cumulative frequencies)\")\n",
    "plt.xlabel(\"dates of issues of the Dispatch\")\n",
    "plt.title(topic + \": \" + topicDic[topic])\n",
    "plt.gca().yaxis.grid(linestyle=':')\n",
    "\n",
    "plt.savefig(dispatchSubfolder + \"graph_dispatch_1860-1864_%s.pdf\" % topic, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the cell below to print out items most representative of this topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mergedTable.sort_values(by=topic, ascending=False)\n",
    "temp[[\"id\", \"date\", \"text\", topic]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can check individual items like this (where the number is the **index** of the row):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(mergedTable[\"text\"][91118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `plotly` library to generat dynamic graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the data for the bar chart\n",
    "bar_data = go.Bar(\n",
    "    x=topicSum[\"month\"], \n",
    "    y=topicSum[topic]\n",
    ")\n",
    "# Create the layout information for display\n",
    "layout = go.Layout(\n",
    "    title=topic+\": \"+topicDic[topic],    \n",
    "    xaxis=dict(title='Dates'),\n",
    "    yaxis=dict(title='Topic Salience')\n",
    ")\n",
    "# These two together create the \"figure\"\n",
    "figure = go.Figure(data=[bar_data], layout=layout)\n",
    "# Use \"iplot\" to create the figure in the Jupyter notebook\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Plotly` also allows one to save a graph into a separate file for sharing and embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(figure, filename=dispatchSubfolder+\"dispatch_1860_1864_%s.html\" % topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of all topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple code for generating graphs for each topic. As you must realize by now, it will be easier to generate these graphs with a loop (something you would definitely do in a regular script). To reduce the amount of code, we can also create a function that will be easier to reuse as a shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphTopic(dataTable, topicDic, topicID, saveOption=True):\n",
    "    plt.plot(dataTable['month'], dataTable[topicID])\n",
    "    plt.ylabel(\"topic salience (cumulative frequencies)\")\n",
    "    plt.xlabel(\"dates of issues of the Dispatch\")\n",
    "    plt.title(topicID + \": \" + topicDic[topicID])\n",
    "    plt.gca().yaxis.grid(linestyle=':')\n",
    "    if not saveOption:\n",
    "        # the following line saves the figure\n",
    "        plt.savefig(dispatchSubfolder + \"graph_dispatch_1860-1864_%s.pdf\" % topicID, dpi=150) \n",
    "        # this one tells matplotlib that you are done with the plot and closes it\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still quickly generate all the graphs and save them on our computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 41, 1):\n",
    "    topic = \"T%02d\" % i\n",
    "    graphTopic(topicSum, topicDic, topic, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T37\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T39\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphTopic(topicSum, topicDic, \"T40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-using our LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained LDA model can be applied to new texts, although this, of course should be done with utmost care. In general, this works as shown below. We'll start with text already split into a list of words, converted into lower case (*original text*: \"Caliph Umar led the conquest of several Iranian provinces.\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = ['caliph', 'umar', 'led', 'conquest', 'several', 'iranian', 'provinces']\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc_bow)\n",
    "print(lda_model.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first list is the words that match words in our model. The second list is the topics and their proportions. You can check the matching words by typing `dictionary[number]` where `number` is the first number in the tuple (`(4429, 1)`). You can also check the ropics by typing `lda_model.print_topic(number)`, where the number is the number of the topic in the tuples of the second liist. Try them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary[4428], dictionary[13911], dictionary[22023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsDicQuick[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for texts from the same period and region should, however, be much better. Let's take another example (just a few lines from [here](https://www.thoughtco.com/the-battle-of-antietam-1773739)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After a summer of defeats in Virginia in the summer of 1862, the Union Army was demoralized in its camps near Washington, D.C. at the beginning of September. On the Confederate side, General Robert E. Lee was hoping to strike a decisive blow by invading the North. Lee's plan was to strike into Pennsylvania, imperiling the city of Washington and forcing an end to the war. The Confederate Army began crossing the Potomac on September 4, and within a few days had entered Frederick, a town in western Maryland. The citizens of the town stared at the Confederates as they passed through, hardly extending the warm welcome Lee had hoped to receive in Maryland. Lee split up his forces, sending part of the Army of Northern Virginia to capture the town of Harpers Ferry and its federal arsenal (which had been the site of John Brown's raid three years earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDoc = [\"after\", \"a\", \"summer\", \"of\", \"defeats\", \"in\", \"virginia\", \"in\", \"the\", \"summer\",\n",
    "           \"of\", \"1862\", \"the\", \"union\", \"army\", \"was\", \"demoralized\", \"in\", \"its\", \"camps\",\n",
    "           \"near\", \"washington\", \"d\", \"c\", \"at\", \"the\", \"beginning\", \"of\", \"september\", \"on\",\n",
    "           \"the\", \"confederate\", \"side\", \"general\", \"robert\", \"e\", \"lee\", \"was\", \"hoping\",\n",
    "           \"to\", \"strike\", \"a\", \"decisive\", \"blow\", \"by\", \"invading\", \"the\", \"north\", \"lee\",\n",
    "           \"s\", \"plan\", \"was\", \"to\", \"strike\", \"into\", \"pennsylvania\", \"imperiling\", \"the\",\n",
    "           \"city\", \"of\", \"washington\", \"and\", \"forcing\", \"an\", \"end\", \"to\", \"the\", \"war\",\n",
    "           \"the\", \"confederate\", \"army\", \"began\", \"crossing\", \"the\", \"potomac\", \"on\", \"september\",\n",
    "           \"4\", \"and\", \"within\", \"a\", \"few\", \"days\", \"had\", \"entered\", \"frederick\", \"a\", \"town\",\n",
    "           \"in\", \"western\", \"maryland\", \"the\", \"citizens\", \"of\", \"the\", \"town\", \"stared\", \"at\",\n",
    "           \"the\", \"confederates\", \"as\", \"they\", \"passed\", \"through\", \"hardly\", \"extending\", \"the\",\n",
    "           \"warm\", \"welcome\", \"lee\", \"had\", \"hoped\", \"to\", \"receive\", \"in\", \"maryland\", \"lee\",\n",
    "           \"split\", \"up\", \"his\", \"forces\", \"sending\", \"part\", \"of\", \"the\", \"army\", \"of\",\n",
    "           \"northern\", \"virginia\", \"to\", \"capture\", \"the\", \"town\", \"of\", \"harpers\", \"ferry\",\n",
    "           \"and\", \"its\", \"federal\", \"arsenal\", \"which\", \"had\", \"been\", \"the\", \"site\", \"of\",\n",
    "           \"john\", \"brown\", \"s\", \"raid\", \"three\", \"years\", \"earlier\"]\n",
    "\n",
    "testDoc = dictionary.doc2bow(testDoc)\n",
    "print(testDoc)\n",
    "print(\"=====\")\n",
    "print(lda_model.get_document_topics(testDoc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the dominant topics? Try your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsDicQuick[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
